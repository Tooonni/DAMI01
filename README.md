# DAMI01 - Berlin Unternehmensstandort Clustering Analyse

## ğŸ“‹ Projektbeschreibung

Dieses Projekt analysiert Unternehmensstandorte in Berlin mittels fortgeschrittener Clustering-Verfahren. Das Ziel ist es, verschiedene Typen von Unternehmensstandorten zu identifizieren und ihre Charakteristika hinsichtlich BevÃ¶lkerungsstruktur, wirtschaftlicher Ausrichtung und rÃ¤umlicher Verteilung zu verstehen.

### ğŸ¯ Forschungsfrage
*Inwiefern lassen sich durch Clusteranalysen verschiedene Typen von Unternehmensstandorten in Berlin identifizieren, und wie unterscheiden sie sich hinsichtlich BevÃ¶lkerungsstruktur und wirtschaftlicher Ausrichtung?*

## ğŸ“Š Datenquellen

- **IHK Berlin Gewerbedaten**: ~350.000 GewerbedatensÃ¤tze mit Informationen zu Unternehmen, Branchen und Standorten
- **Bodenrichtwerte Berlin**: Immobilienwerte nach Bezirken und Stadtteilen
- **Einwohnerdichte 2023**: Demografische Daten zur BevÃ¶lkerungsverteilung in Berlin
- **WZ-2008 Klassifikationen**: Standardisierte Wirtschaftszweig-Klassifizierungen

## ğŸ—‚ï¸ Projektstruktur

```
DAMI01/
â”œâ”€â”€ README.md                                    # Projektdokumentation
â”œâ”€â”€ requirements.txt                             # Python-AbhÃ¤ngigkeiten
â”œâ”€â”€ input/                                       # Rohdaten und verarbeitete Daten
â”‚   â”œâ”€â”€ raw/                                     # Originaldaten
â”‚   â”œâ”€â”€ clean/                                   # Bereinigte Daten
â”‚   â”œâ”€â”€ ihk_gewerbedaten_with_brw_einwohnerdichte.csv.gz  # Hauptdatensatz
â”‚   â”œâ”€â”€ klassifikationen-wz-2008.pdf            # Wirtschaftszweig-Klassifikationen
â”‚   â””â”€â”€ nachweis_brw.png                         # Bodenrichtwert-Nachweis
â””â”€â”€ notebooks/                                   # Jupyter Notebooks
    â”œâ”€â”€ main.ipynb                               # Hauptanalyse mit Clustering
    â”œâ”€â”€ data_preprocessing_ihk_gewerbedaten.ipynb # IHK-Daten Vorverarbeitung
    â”œâ”€â”€ data_preprocessing_bodenrichtwert.ipynb  # Bodenrichtwert-Integration
    â””â”€â”€ data_preprocessing_einwohnerdichte.ipynb # Demografische Daten-Integration
```

## ğŸ› ï¸ Technologie-Stack

### Machine Learning & Data Science
- **pandas** (2.2.3) - Datenmanipulation und -analyse
- **numpy** (2.2.5) - Numerische Berechnungen
- **scikit-learn** (1.6.1) - Machine Learning Algorithmen
- **matplotlib** (3.10.1) - Datenvisualisierung
- **seaborn** (0.13.2) - Statistische Datenvisualisierung

### Clustering-Algorithmen
- **K-Means** - Zentroid-basiertes Clustering
- **Gaussian Mixture Models (GMM)** - Probabilistisches Clustering
- **DBSCAN** - Dichtebasiertes Clustering
- **HDBSCAN** (0.8.40) - Hierarchisches dichtebasiertes Clustering

### Geospatiale Analyse
- **geopandas** (1.1.1) - Geospatiale Datenverarbeitung
- **folium** (0.20.0) - Interaktive Karten
- **contextily** (1.6.2) - KartenhintergrÃ¼nde

### Evaluationsmetriken
- **Silhouette Score** - Cluster-QualitÃ¤tsbewertung
- **Calinski-Harabasz Index** - Cluster-Separation
- **Davies-Bouldin Index** - Cluster-Kompaktheit
- **Hopkins Statistik** - Cluster-Tendenz

## ğŸš€ Setup und Installation

### Virtual Environment
1. **Erstelle Virtual Environment**:
   ```bash
   python3 -m venv .venv
   ```

2. **Aktiviere Virtual Environment**:
   ```bash
   # macOS/Linux
   source .venv/bin/activate
   
   # Windows
   .venv\Scripts\activate
   ```

3. **Installiere AbhÃ¤ngigkeiten**:
   ```bash
   pip install -r requirements.txt
   ```

4. **ÃœberprÃ¼fe Installation**:
   ```bash
   pip freeze --local
   ```

### Jupyter Notebook starten
```bash
jupyter notebook notebooks/
```

## ğŸ“ˆ Analyse-Pipeline

### 1. Datenvorverarbeitung
- **IHK-Daten**: Bereinigung, Kategorisierung von Branchen, Altersberechnung
- **Bodenrichtwerte**: Geocoding und Zuordnung zu Unternehmensstandorten
- **Einwohnerdichte**: Integration demografischer Merkmale

### 2. Feature Engineering
- Normalisierung numerischer Variablen
- One-Hot-Encoding kategorialer Variablen
- PCA-Dimensionsreduktion fÃ¼r Visualisierung
- AusreiÃŸer-Behandlung mittels IQR-Methode

### 3. Clustering-Analyse
- **K-Means**: Optimierung via Elbow-Methode und Silhouette-Analyse
- **GMM**: BIC/AIC-basierte Modellauswahl mit verschiedenen Kovarianz-Typen
- **DBSCAN**: Îµ-Optimierung durch k-Distanz-Analyse

### 4. Evaluation & Interpretation
- Umfassende Cluster-QualitÃ¤tsbewertung
- GeschÃ¤ftsorientierte Interpretation der Cluster
- Visualisierung in 2D/3D-Raum
- Geospatiale Cluster-Darstellung

## ğŸ“Š Hauptergebnisse

### Cluster-Charakteristika
Das optimierte Clustering identifiziert verschiedene Unternehmensstandort-Typen:

1. **Etablierte GeschÃ¤ftszentren**: Hoher Bodenrichtwert, reife Unternehmen
2. **Emerging Tech-Hubs**: Junge Unternehmen, innovative Branchen  
3. **Traditionelle Gewerbegebiete**: Produktion/Handel, mittlere Immobilienwerte
4. **Dichtebasierte Cluster**: RÃ¤umlich konzentrierte Unternehmensansiedlungen

### Performance-Metriken
- **Bester Algorithmus**: DBSCAN (Silhouette Score: 0.519)
- **Cluster-Anzahl**: 2-20 je nach Algorithmus
- **Datenabdeckung**: 50.000 Sample aus 350.000 Unternehmen

## ğŸ’¡ Business Insights

### Handlungsempfehlungen
1. **StandortfÃ¶rderung**: Gezielte UnterstÃ¼tzung basierend auf Cluster-Profilen
2. **Stadtplanung**: Infrastrukturentwicklung fÃ¼r identifizierte Hotspots
3. **Unternehmensberatung**: Standortempfehlungen basierend auf Branche und GrÃ¶ÃŸe
4. **WirtschaftsfÃ¶rderung**: Cluster-spezifische FÃ¶rderprogramme

### Methodische Erkenntnisse
- Silhouette Score als robusteste Bewertungsmetrik
- DBSCAN optimal fÃ¼r dichtebasierte Standortmuster
- Bodenrichtwert als wichtiger Differenzierungsfaktor
- Demografische Merkmale verstÃ¤rken Cluster-Interpretierbarkeit

## ğŸ”¬ Wissenschaftlicher Ansatz

### Methodische RigorositÃ¤t
- Multiple Clustering-Algorithmen fÃ¼r Robustheit
- Systematische Hyperparameter-Optimierung
- Kreuzvalidierung verschiedener Bewertungsmetriken
- Statistische Signifikanz-Tests

### Reproduzierbarkeit
- VollstÃ¤ndig dokumentierte Datenverarbeitungs-Pipeline
- Versionierte AbhÃ¤ngigkeiten
- Standardisierte Random Seeds
- Modular aufgebauter, wiederverwendbarer Code

## ğŸ“ Datenmanagement

### Input-Verzeichnis Struktur
- Komprimierte Formate (.csv.gz) fÃ¼r groÃŸe DatensÃ¤tze
- Dokumentation der Datenquellen und -transformationen

### DatenqualitÃ¤t
- Systematische Missing-Value-Behandlung
- AusreiÃŸer-Erkennung und -Behandlung
- Datentyp-Validierung
- Konsistenz-Checks zwischen DatensÃ¤tzen

## ğŸ“ Verwendung fÃ¼r Lehre/Forschung

Dieses Projekt eignet sich hervorragend fÃ¼r:
- **Data Mining Kurse**: Clustering-Verfahren in der Praxis
- **Urban Analytics**: Anwendung von ML auf Stadtdaten
- **Business Intelligence**: Datengetriebene Standortanalysen
- **Geospatiale Analyse**: Integration rÃ¤umlicher und betriebswirtschaftlicher Daten

## ğŸ“ Weitere Informationen

FÃ¼r Fragen zur Implementierung, Datenquellen oder methodischen Details kontaktieren Sie den Projektverantwortlichen.

---